{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d53e21-91e2-47d1-b5d4-9c936169237c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "#Multi-level thresholding image segmentation Cross Entropy\n",
    "class MLTHIMS_CE(object):\n",
    "    \"\"\"\n",
    "    Cross entropy function for multi-level thresholding image segmentation\n",
    "    Created on  JUne 15  2022\n",
    "    \n",
    "    @author: Thaer Thaher\n",
    "    \n",
    "    % _____________________________________________________\n",
    "    % Main paper:\n",
    "    % \n",
    "    % \n",
    "    % \n",
    "    % _____________________________________________________\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,hist, dim = 10):\n",
    "        \"\"\"\n",
    "        Constructs a PSO algorithm\n",
    "        USAGE: pygmo.problem(pygmo.cross_entropy(dim = 10))\n",
    "        \n",
    "        * dim (int) – problem dimension (number of thresholds)\n",
    "        * hist (array) – INput image historgram\n",
    "        \"\"\"\n",
    "        \n",
    "        #We start defining the problem ’private’ data members\n",
    "        self.__dim = dim\n",
    "        self.__hist = hist\n",
    "\n",
    "        \n",
    "    # Reimplement the virtual method called fitness that defines the objective function.\n",
    "    # used to return the fitness of the input decision vector\n",
    "    def fitness(self,x):\n",
    "        \n",
    "        \"\"\" x is the input decision vector i.e., (candidate solution) \"\"\"\n",
    "        x.sort()\n",
    "        f = self.cross_entropy(x, self.__hist)\n",
    "        return [f]\n",
    "        \"\"\"\n",
    "        f = 0;\n",
    "        for i in range(self.__dim):\n",
    "            f = f + (x[i])*(x[i])\n",
    "            #note that we return a tuple with one element only. In PyGMO the objective functions\n",
    "            #return tuples so that multi-objective optimization is also possible.\n",
    "        return (f,)\n",
    "        \"\"\"\n",
    "        \n",
    "    ############################################\n",
    "      \n",
    "    # return the box bounds of the problem, , which also implicitly define the dimension of the problem   \n",
    "    def get_bounds(self):\n",
    "        \n",
    "        return ([1] * self.__dim,[256] * self.__dim)\n",
    "        \n",
    "    \n",
    "    def get_name(self):\n",
    "        return \"Cross Entropy\"\n",
    "    \n",
    "    def get_extra_info(self):\n",
    "        \n",
    "        return \"\\n\\t Problem dimension: \" + str(self.__dim)\n",
    "    \n",
    "    \n",
    "    def cross_entropy(self, x , h):\n",
    "        \"\"\"\n",
    "        * x (array) – decision vector\n",
    "        * h (array): Image histogram\n",
    "        \"\"\"\n",
    "        st = len(x)\n",
    "        nu = np.zeros(st+1)\n",
    "    \n",
    "        for i in range(st+1):\n",
    "            #print(i)\n",
    "            if i == 0:                 # First Part\n",
    "                ti = x[i]\n",
    "                ti_1 = 1\n",
    "                #print(ti_1)\n",
    "                #print(mEin(ti_1,ti,h))\n",
    "                #nu(i) = 5\n",
    "                #nu[i] = mEin(ti_1,ti,h)*(math.log(mEin(ti_1,ti,h)/mZero(ti_1,ti,h))); #cross entropy\n",
    "            \n",
    "            \n",
    "            elif i > (st-1):           # Last Part\n",
    "                ti = 256\n",
    "                ti_1 = x[i-1]\n",
    "                #print(ti_1)\n",
    "                #print(mEin(ti_1,ti,h))\n",
    "                #nu[i] = mEin(ti_1,ti,h)*(math.log(mEin(ti_1,ti,h)/mZero(ti_1,ti,h))); #cross entropy\n",
    "            \n",
    "            else:                     # Original\n",
    "                ti = x[i]\n",
    "                ti_1 = x[i-1]\n",
    "                #print(ti_1)\n",
    "                #print(mEin(ti_1,ti,h))\n",
    "                #nu[i] = mEin(ti_1,ti,h)*(math.log(mEin(ti_1,ti,h)/mZero(ti_1,ti,h))); #cross entropy\n",
    "                    \n",
    "            try:\n",
    "                nu[i] = self.mEin(round(ti_1),round(ti),h)*(math.log(self.mEin(round(ti_1),round(ti),h) / self.mZero(round(ti_1),round(ti),h))) #cross entropy\n",
    "            except ZeroDivisionError:\n",
    "                nu[i] = 0\n",
    "            \n",
    "            \n",
    "        sumNU=np.sum(nu)\n",
    "        \n",
    "        if (np.isnan(sumNU)):        \n",
    "            fit=-1*sumNU\n",
    "        else:\n",
    "            fit=-1*sumNU;    \n",
    "        #print(\"fitness = \", fit)\n",
    "        return fit\n",
    "\n",
    "\n",
    "    def mEin(self,aa,bb,ih):\n",
    "        bm_1 = bb-1\n",
    "        #print(aa)\n",
    "        #print(bm_1)\n",
    "        dif_bm_1 = abs(aa-bb)\n",
    "        #print(dif_bm_1)\n",
    "        inten = np.linspace(aa,bm_1,dif_bm_1)\n",
    "        #print(\"len of inten\",len(inten))\n",
    "        #print(len(inten))\n",
    "        #inten = np.transpose(inten)\n",
    "        #print(inten)\n",
    "    \n",
    "        H = ih[aa-1 : bm_1]\n",
    "        #print(\"len of h\", len(H))\n",
    "        uu = np.multiply(inten,H)\n",
    "        u = sum(uu)\n",
    "    \n",
    "        return u\n",
    "\n",
    "    def mZero(self,aa,bb,ih):\n",
    "        bm_1=bb-1\n",
    "        h=ih[aa-1:bm_1]\n",
    "        u=  sum(h)\n",
    "    \n",
    "        return u"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
